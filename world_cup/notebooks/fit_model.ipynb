{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We are going to load the data then do a little pre-processing. The pre-processing does two things:\n",
    "\n",
    "1. Convert the prior ranking to the range -1 and 1 based on Gelman's rescale logic outlined [here](http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf).\n",
    "2. Based on the Soccer Power Index, work out which team is the favourite for each game and rank the games by those expected to be close and those not. This is mainly for plotting purposes later on and not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = np.loadtxt(\"../data/soccerpowerindex.txt\", dtype=str)\n",
    "num_teams = len(teams)\n",
    "\n",
    "raw_prior_score = np.arange(32, 0, -1)\n",
    "prior_score = (raw_prior_score - np.mean(raw_prior_score)) / (\n",
    "    2 * np.std(raw_prior_score, ddof=1)\n",
    ")\n",
    "ranking_dict = {k: v for k, v in zip(teams, range(1, 33))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"../data/worldcup2012.txt\", delim_whitespace=True, header=None\n",
    ")\n",
    "data.columns = [\"team_1\", \"team_1_score\", \"team_2\", \"team_2_score\"]\n",
    "num_games = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work out favourites for each game and sort dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"team_1_rank\"] = data[\"team_1\"].apply(lambda x: ranking_dict[x])\n",
    "data[\"team_2_rank\"] = data[\"team_2\"].apply(lambda x: ranking_dict[x])\n",
    "team_1_fave = data[\"team_1_rank\"].values < data[\"team_2_rank\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cols(\n",
    "    df, team_1_fave_mask, t1_col, t2_col, fave_name, underdog_name\n",
    "):\n",
    "    df[fave_name] = df.loc[team_1_fave_mask, t1_col]\n",
    "    df.loc[~team_1_fave_mask, fave_name] = df.loc[~team_1_fave_mask, t2_col]\n",
    "    df[underdog_name] = df.loc[~team_1_fave_mask, t1_col]\n",
    "    df.loc[team_1_fave_mask, underdog_name] = df.loc[team_1_fave_mask, t2_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cols(data, team_1_fave, \"team_1\", \"team_2\", \"fave\", \"underdog\")\n",
    "create_cols(\n",
    "    data,\n",
    "    team_1_fave,\n",
    "    \"team_1_score\",\n",
    "    \"team_2_score\",\n",
    "    \"fave_score\",\n",
    "    \"underdog_score\",\n",
    ")\n",
    "create_cols(\n",
    "    data,\n",
    "    team_1_fave,\n",
    "    \"team_1_rank\",\n",
    "    \"team_2_rank\",\n",
    "    \"fave_rank\",\n",
    "    \"underdog_rank\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"abs_rank_diff\"] = np.abs(\n",
    "    data[\"team_1_rank\"].values - data[\"team_2_rank\"].values\n",
    ")\n",
    "data[\"fave_underdog_score_diff\"] = (\n",
    "    data[\"fave_score\"].values - data[\"underdog_score\"].values\n",
    ")\n",
    "data = data.sort_values([\"abs_rank_diff\", \"fave\"], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we set the degrees of freedom for the sampling distribution to be 7 (an arbitrary choice) allowing for outliers in scores but nothing too extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_of_freedom = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stan model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to put team 1 always as the favourite and team 2 as the underdog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_data = {\n",
    "    \"num_teams\": num_teams,\n",
    "    \"num_games\": num_games,\n",
    "    \"team_1_rank\": data[\"fave_rank\"].values.astype(np.uint8),\n",
    "    \"team_1_score\": data[\"fave_score\"].values,\n",
    "    \"team_2_rank\": data[\"underdog_rank\"].values.astype(np.uint8),\n",
    "    \"team_2_score\": data[\"underdog_score\"].values,\n",
    "    \"prior_score\": prior_score,\n",
    "    \"deg_freedom\": degrees_of_freedom,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pystan.StanModel(file=\"../stan_models/worldcup-no-sqrt.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit = model.sampling(data=stan_data)\n",
    "params = fit.extract(permuted=True)\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz_inf = arviz.convert_to_inference_data(fit)\n",
    "summary_df = (\n",
    "    arviz.summary(arviz_inf)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"parameter\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_trace(fit, var_names=(\"b\", \"sigma_a\", \"sigma_y\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "for i in range(num_teams):\n",
    "    a_mean = params[\"a\"][:, i].mean()\n",
    "    a_sd = float(summary_df.loc[summary_df[\"parameter\"] == f\"a[{i}]\", \"sd\"])\n",
    "    ax.scatter(a_mean, i + 1)\n",
    "    ax.hlines(i + 1, a_mean - a_sd, a_mean + a_sd)\n",
    "\n",
    "plt.vlines(0, 1, num_teams, linestyle=\"--\", alpha=0.5)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.yticks(range(1, num_teams + 1), teams)\n",
    "plt.title(\"Team quality estimate +/- 1 SE\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the 95% predictive interval for each game's score difference based on the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.95\n",
    "\n",
    "games = [\n",
    "    f\"{a} vs. {b}\"\n",
    "    for a, b in zip(data[\"fave\"].values, data[\"underdog\"].values)\n",
    "]\n",
    "fig, ax = plt.subplots(figsize=(10, 16))\n",
    "for i in range(num_games):\n",
    "    lq, uq = np.quantile(\n",
    "        params[\"ypred\"][:, i], q=[(1 - q) / 2, q + (1 - q) / 2]\n",
    "    )\n",
    "    ax.scatter(data[\"fave_underdog_score_diff\"].values[i], i + 1)\n",
    "    ax.hlines(i + 1, lq, uq, alpha=0.75)\n",
    "\n",
    "    plt.vlines(0, 1, num_games, linestyle=\"--\", alpha=0.5)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlim(-8, 8)\n",
    "plt.yticks(range(1, num_games + 1), games)\n",
    "plt.title(\n",
    "    f\"Score differentials vs. \\n {q*100:.0f}% predictive interval from model\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
